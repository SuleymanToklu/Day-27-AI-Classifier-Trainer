import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
import os
import gradio as gr
from PIL import Image
import numpy as np
from pathlib import Path
import requests
from io import BytesIO
import shutil
import time
import re
from ddgs import DDGS

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(32 * 32 * 32, 256)
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(256, 2)

    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        x = x.view(-1, 32 * 32 * 32)
        x = self.relu3(self.fc1(x))
        x = self.fc2(x)
        return x

def slugify(text):
    text = text.lower()
    text = re.sub(r'[^a-z0-9]+', '_', text).strip('_')
    return text

def download_images(search_term, folder, max_images=40):
    path = Path(folder)
    if path.exists():
        shutil.rmtree(path)
    path.mkdir(exist_ok=True, parents=True)
    
    downloaded_count = 0
    with DDGS() as ddgs:
        ddgs_images_gen = ddgs.images(
            query=search_term,
            region='tr-tr',
            max_results=int(max_images * 1.5)
        )
        
        for r in ddgs_images_gen:
            if downloaded_count >= max_images:
                break
            try:
                response = requests.get(r['image'], timeout=10)
                response.raise_for_status()
                img = Image.open(BytesIO(response.content)).convert("RGB")
                img.save(path / f"{downloaded_count + 1}.jpg")
                downloaded_count += 1
            except Exception as e:
                pass 
            
    return f"'{folder}' klasÃ¶rÃ¼ne {downloaded_count} adet resim indirildi."

def setup_dataset(class1_query, class2_query, num_images_per_class, split_ratio=0.8):
    base_dir = Path('dataset')
    if base_dir.exists():
        shutil.rmtree(base_dir)

    yield "Veri seti klasÃ¶rleri temizleniyor ve hazÄ±rlanÄ±yor..."

    class1_name = slugify(class1_query)
    class2_name = slugify(class2_query)
    
    temp_class1_dir = base_dir / "temp" / class1_name
    temp_class2_dir = base_dir / "temp" / class2_name
    
    yield f"'{class1_query}' iÃ§in indirme baÅŸlÄ±yor..."
    msg1 = download_images(class1_query, temp_class1_dir, num_images_per_class)
    yield f"'{class1_query}' iÃ§in indirme tamamlandÄ±. ({msg1})"
    
    time.sleep(2) 
    
    yield f"'{class2_query}' iÃ§in indirme baÅŸlÄ±yor..."
    msg2 = download_images(class2_query, temp_class2_dir, num_images_per_class)
    yield f"'{class2_query}' iÃ§in indirme tamamlandÄ±. ({msg2})"

    yield "Ä°ndirilen resimler 'train' ve 'val' olarak ayrÄ±lÄ±yor..."
    for phase in ['train', 'val']:
        (base_dir / phase / class1_name).mkdir(exist_ok=True, parents=True)
        (base_dir / phase / class2_name).mkdir(exist_ok=True, parents=True)
        
    def split_files(source_dir, train_dir, val_dir):
        files = list(source_dir.glob("*.jpg"))
        split_point = int(len(files) * split_ratio)
        train_files, val_files = files[:split_point], files[split_point:]
        for f in train_files: shutil.copy(f, train_dir / f.name)
        for f in val_files: shutil.copy(f, val_dir / f.name)
            
    split_files(temp_class1_dir, base_dir / 'train' / class1_name, base_dir / 'val' / class1_name)
    split_files(temp_class2_dir, base_dir / 'train' / class2_name, base_dir / 'val' / class2_name)
    
    shutil.rmtree(base_dir / "temp")
    
    yield f"ğŸ‰ Veri seti baÅŸarÄ±yla oluÅŸturuldu! SÄ±nÄ±flar: '{class1_name}', '{class2_name}'"

def train_model(data_dir, num_epochs=10):
    yield "EÄŸitim baÅŸlÄ±yor... Veriler yÃ¼kleniyor..."
    
    data_transforms = {
        'train': transforms.Compose([transforms.RandomResizedCrop(128), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
        'val': transforms.Compose([transforms.Resize(150), transforms.CenterCrop(128), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
    }
    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}
    dataloaders = {x: DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=0) for x in ['train', 'val']}
    class_names = image_datasets['train'].classes
    with open("class_names.txt", "w") as f: f.write(",".join(class_names))
    
    yield f"Veriler yÃ¼klendi. SÄ±nÄ±flar: {class_names}. Cihaz hazÄ±rlanÄ±yor..."
    
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    model = SimpleCNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    yield f"Model eÄŸitime hazÄ±r. Cihaz: {device}. Toplam Epoch: {num_epochs}"

    for epoch in range(num_epochs):
        epoch_info = f'Epoch {epoch+1}/{num_epochs}\n' + ('-' * 20)
        
        for phase in ['train', 'val']:
            if phase == 'train': model.train()
            else: model.eval()
            running_loss, running_corrects = 0.0, 0
            for inputs, labels in dataloaders[phase]:
                inputs, labels = inputs.to(device), labels.to(device)
                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            epoch_loss = running_loss / len(image_datasets[phase])
            epoch_acc = running_corrects.double() / len(image_datasets[phase])
            
            epoch_info += f'\n{phase.capitalize()} | KayÄ±p: {epoch_loss:.4f} - BaÅŸarÄ±: {epoch_acc:.4f}'
            yield epoch_info

    torch.save(model.state_dict(), 'model.pth')
    
    global TRAINED_MODEL, CLASS_NAMES
    TRAINED_MODEL = model
    CLASS_NAMES = class_names

    yield f"âœ… EÄŸitim tamamlandÄ±! Model 'model.pth' olarak kaydedildi."

def start_training_wrapper():
    if not os.path.exists('dataset/train'):
        return "Hata: Ã–nce veri setini oluÅŸturmalÄ±sÄ±nÄ±z."
    yield from train_model('dataset')

TRAINED_MODEL, CLASS_NAMES = None, None
MODEL_PATH, CLASS_NAMES_PATH = "model.pth", "class_names.txt"

def predict(image):
    if TRAINED_MODEL is None or CLASS_NAMES is None: return "Model henÃ¼z eÄŸitilmedi veya yÃ¼klenemedi."
    transform = transforms.Compose([transforms.Resize(150), transforms.CenterCrop(128), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
    image = Image.fromarray(image.astype('uint8'), 'RGB')
    image = transform(image).unsqueeze(0)
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    image = image.to(device)
    with torch.no_grad():
        outputs = TRAINED_MODEL(image)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
    confidences = {CLASS_NAMES[i]: float(probabilities[i]) for i in range(len(CLASS_NAMES))}
    return confidences

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– Otomatik GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rÄ±cÄ± EÄŸitmeni ğŸ› ï¸")
    gr.Markdown("Bu uygulama, internetten belirttiÄŸiniz iki sÄ±nÄ±f iÃ§in resim toplar, bir model eÄŸitir ve tahmin yapmanÄ±zÄ± saÄŸlar.")

    with gr.Tab("AdÄ±m 1: Veri Topla"):
        class1_input = gr.Textbox(label="SÄ±nÄ±f 1 Arama Terimi", placeholder="Ã–rn: Isparta GÃ¼lÃ¼")
        class2_input = gr.Textbox(label="SÄ±nÄ±f 2 Arama Terimi", placeholder="Ã–rn: Lavanta TarlasÄ±")
        num_images_slider = gr.Slider(minimum=20, maximum=100, value=40, step=5, label="Her SÄ±nÄ±f Ä°Ã§in Ä°ndirilecek Resim SayÄ±sÄ±")
        data_button = gr.Button("Veri Setini OluÅŸtur")
        data_output = gr.Textbox(label="Veri Toplama Durumu", interactive=False, lines=5)
        data_button.click(setup_dataset, inputs=[class1_input, class2_input, num_images_slider], outputs=data_output)
        
        with gr.Accordion("â„¹ï¸ Bu AdÄ±mda Ne Oluyor?", open=False):
            gr.Markdown("""
            Bu adÄ±mda, girdiÄŸiniz arama terimleri kullanÄ±larak internetten otomatik olarak resimler indirilir.
            - **KÃ¼tÃ¼phane:** `ddgs` (DuckDuckGo Search)
            - **Ä°ÅŸlem:** Belirtilen sayÄ±da resim bulunur, indirilir ve `dataset` klasÃ¶rÃ¼ altÄ±nda `train` (eÄŸitim) ve `val` (doÄŸrulama) olarak ikiye ayrÄ±lÄ±r.
            - **`time.sleep(2)`:** Ä°ki arama arasÄ±nda eklenen bu kÃ¼Ã§Ã¼k bekleme, arama motoru tarafÄ±ndan 'rate limit'e (hÄ±z sÄ±nÄ±rÄ±na) takÄ±lmamÄ±zÄ± engeller.
            """)

    with gr.Tab("AdÄ±m 2: Modeli EÄŸit"):
        train_button = gr.Button("EÄŸitimi BaÅŸlat")
        train_output = gr.Textbox(label="EÄŸitim Durumu", interactive=False, lines=10)
        train_button.click(start_training_wrapper, outputs=train_output)

        with gr.Accordion("â„¹ï¸ Bu AdÄ±mda Ne Oluyor?", open=False):
            gr.Markdown("""
            Bu adÄ±mda, topladÄ±ÄŸÄ±mÄ±z resimleri kullanarak bir **EvriÅŸimli Sinir AÄŸÄ± (Convolutional Neural Network - CNN)** modelini sÄ±fÄ±rdan eÄŸitiyoruz.
            - **KÃ¼tÃ¼phane:** `PyTorch`
            - **Epoch:** Veri setinin tamamÄ±nÄ±n model tarafÄ±ndan bir kez iÅŸlenmesi demektir.
            - **Loss (KayÄ±p):** Modelin tahminlerinin ne kadar 'yanlÄ±ÅŸ' olduÄŸunu Ã¶lÃ§en bir deÄŸerdir. **DÃ¼ÅŸÃ¼k olmasÄ± iyidir.**
            - **Accuracy (BaÅŸarÄ±):** Modelin tahminlerinin ne kadarÄ±nÄ±n 'doÄŸru' olduÄŸunu gÃ¶steren bir orandÄ±r. **YÃ¼ksek olmasÄ± iyidir.**
            """)

    with gr.Tab("AdÄ±m 3: Tahmin Yap"):
        image_input = gr.Image(type="numpy", label="Bir Resim YÃ¼kleyin")
        label_output = gr.Label(num_top_classes=2)
        predict_button = gr.Button("Tahmin Et")
        predict_button.click(predict, inputs=image_input, outputs=label_output)

        with gr.Accordion("â„¹ï¸ Bu AdÄ±mda Ne Oluyor?", open=False):
            gr.Markdown("""
            Bu adÄ±mda, az Ã¶nce eÄŸittiÄŸimiz model ile daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi bir resmi sÄ±nÄ±flandÄ±rÄ±yoruz. Bu iÅŸleme **Ã§Ä±karÄ±m (inference)** denir.
            - **Ä°ÅŸlem:** YÃ¼klenen resim, modelin anlayacaÄŸÄ± formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve eÄŸittiÄŸimiz sinir aÄŸÄ±ndan geÃ§irilir.
            - **SonuÃ§:** Model, resmin her bir sÄ±nÄ±fa ait olma olasÄ±lÄ±ÄŸÄ±nÄ± bir yÃ¼zde olarak hesaplar (`Softmax`). En yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±f, modelin tahmini olarak kabul edilir.
            """)

try:
    if os.path.exists(MODEL_PATH) and os.path.exists(CLASS_NAMES_PATH):
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        TRAINED_MODEL = SimpleCNN().to(device)
        TRAINED_MODEL.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        TRAINED_MODEL.eval()
        with open(CLASS_NAMES_PATH, "r") as f: CLASS_NAMES = f.read().strip().split(',')
        print("Ã–nceden eÄŸitilmiÅŸ model ve sÄ±nÄ±flar baÅŸarÄ±yla yÃ¼klendi.")
except Exception as e:
    TRAINED_MODEL, CLASS_NAMES = None, None
    print(f"Ã–nceden eÄŸitilmiÅŸ model yÃ¼klenirken hata oluÅŸtu: {e}")

if __name__ == "__main__":
    demo.launch()